# Word2Vec (CBOW) from Scratch with Wikipedia Data

A from-scratch implementation of the Continuous Bag of Words (CBOW) variant of Word2Vec, trained on Wikipedia text data.  
The project demonstrates low-level neural embedding learning and visualizes learned word vectors using t-SNE.

---

## 📁 Project Structure

All logic — from data scraping and preprocessing to model training and visualization — is implemented in a single Jupyter Notebook for clarity and step-by-step demonstration.

Python modules (e.g., `model.py`, `train.py`, etc) have been initialized and will be modularized in upcoming updates.

> 🔧 Until then, refer to the notebook for the full working implementation.

---

## Features

- ✅ CBOW model implemented from scratch using PyTorch
- 🌐 Raw Wikipedia text fetched via `wikipedia-api`
- 🧭 Visualized embeddings using t-SNE 
- 🗂️ Modular Python scripts planned
- 🖥️ Planned: simple Gradio demo to explore word similarities

